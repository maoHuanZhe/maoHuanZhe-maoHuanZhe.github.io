---
title: 合并请求
date: 2022-04-19 20:50:57
permalink: /pages/83d623/
categories:
  - Elasticsearch
  - 提升性能
tags:
  - 
author: 
  name: 樊光瑞
  link: https://github.com/maoHuanZhe
---
为了获得更快的索引速度，你能做的一项优化是通过 `bulk` 批量 `API`，一次发送多篇文档进行索引。这个操作将节省网络来回的开销，并产生更大的索引吞吐量。一个单独的批量可以接受任何索引操作。例如，你可以创建或者重写文档。也可以将 `update` 或 `delete` 操作加入批量，不限于索引操作。
如果应用需要一次发送多条 `get` 或 `search` 操作，也有对应的批量处理：多条获取和多条搜索 `API`。 稍后我们将探索这些，不过这里先从 `bulk` 批量 `API` 开始，因为在生产环境中这是大多数情况下索引的“方式”。
## 批量索引、更新和删除
在本书中，到目前为止你每次只索引一篇文档。如果随便玩玩这是没什么问题的，但是如此操作意味着两个方面的性能损失。
- 应用程序必须等待 `Elasticsearch` 的答复，才能继续运行下去。
- 对于每篇被索引的文档，`Elasticsearch` 必须处理请求中的所有数据
如果需要更快的索引速度，`Elasticsearch` 提供了批量(`bulk`)`API`．你可以用来一次索引多篇文档，如图 10-1 所示。
如图 10-1 所示，你可以使用 `HTTP` 完成这个操作，就像索引单篇文档那样，而且你将获得包含全部索引请求结果的答复。
::: center
![Elasticsearch](https://cdn.jsdelivr.net/gh/maoHuanZhe/image@main/20220426/Elasticsearch.3nl0r9d6ywg0.webp)
图 10-1 批量索引允许你在同一个请求中发送多篇文档
:::
### 使用批量的索引
在下面的代码清单 10-1 中，你将批量索引两篇文档。为了实现这个目标，你需要发送 `HTTP POST` 请求到 `_bulk` 端点，数据也要按照一定的格式。格式有如下的要求。
- 每个索引请求由两个 `JSON ` 文档组成，由换行符分隔开来：一个是操作(本例中是索引 `index`)和元数据(如索引和文档 `ID`)，另一个是文档的内容。
- 每行只有一个 `JSON` 文档。这意味着每行需要使用换行符(`\n`，或者是 `ASCII` 码 10)结尾，包括整个批量请求的最后一行。
::: warning 代码清单 10-1 在单个批量请求中索引两篇文档
```
POST /_bulk
{"index":{"_index":"get-together","_id":"10"}}
{"name":"Elastcsearch Bucharest"}
{"index":{"_index":"get-together","_id":"11"}}
{"name":"Big DAta Bucharest"}
```
:::
对于两个索引请求中的每一个而言，在第一行你添加了操作类型和一些元数据。主要的字段名是操作类型：它表示 `Elastiesearch` 要如何处理后面紧跟的数据。现在，你已经使用了 `index` 来进行索引，如果同样 `ID` 的文档已经存在，那么这个操作将使用新数据覆盖原有文档。可以将操作改为创建 `create`，确保已有的文档不会被覆盖。稍后会介绍，你也可以使用 `update` 和 `delete`，一次处理多篇文档。
这里 `_index` 表示每篇文档索引到何处。可以在 `URL` 中放入索引的名称。这使得它们成为 `bulk` 中每次操作的默认索引。例如：
```
POST /get-together/_bulk
```
这样你就可以不用在请求本身中放入 `_index`。不过，如果在请求本身中指定了索引的值，那么这些值会覆盖 `URL ` 中所带的值。
这里 `_id` 字段意味着你索引的文档 `ID`。如果你省略了这个参数，`Elasticsearch` 会自动地生成一个 `ID`，在你的文档没有唯一 `ID` 的时候，这一点很有帮助。举个例子，对于日志记录而言，自动生成的 `ID` 就已经很好了，因为日志记录通常无须有意义的唯一 `ID`，也没有必要通过 ID 来检索它们。
如果无须提供 `ID`，而且你将全部的文档索引到同一个索引中，那么代码清单 10-1 中的批量请求就会简单得多，如代码清单 10-2 所示。
::: warning 代码清单 10-2 使用自动ID，在同一个索引中索引两篇文档
```
POST /get-together/_bulk
{"index":{}}
{"name":"Elasticsearch Bucharest"}
{"index":{}}
{"name":"Big Data Bucharest"}
```
:::
这个批量操作的结果应该是一个 `JSON` 对象，包含了索引花费的时间，以及针对每个操作的回复。还有一个名为 `errors` 的错误旗标，表示是否有任何一个操作失败了。整体的回复看上去是这样的.
```
{
  "took" : 43,
  "errors" : false,
  "items" : [
    {
      "index" : {
        "_index" : "get-together",
        "_id" : "0AyoToABfFQLtETFnp-C",
        "_version" : 1,
        "result" : "created",
        "_shards" : {
          "total" : 2,
          "successful" : 2,
          "failed" : 0
        },
        "_seq_no" : 4,
        "_primary_term" : 2,
        "status" : 201
      }
    },
    {
      "index" : {
        "_index" : "get-together",
        "_id" : "0QyoToABfFQLtETFnp-C",
        "_version" : 1,
        "result" : "created",
        "_shards" : {
          "total" : 2,
          "successful" : 2,
          "failed" : 0
        },
        "_seq_no" : 5,
        "_primary_term" : 2,
        "status" : 201
      }
    }
  ]
}
```
请注意由于你使用了自动的 `ID` 生成，操作 `index` 会被转变为 `create`。如果一篇文档由于某种原因无法索引，那么并不意味着整个批量操作失败了，因为同一个批量中的各项是彼此独立的。这也是为什么每个操作都给你了一个请求回复，而不是整个批量给你一个单独的回复。在你的应用中，你可以使用回复的 `JSON` 来确定哪些操作成功了而哪些操作失败了。
::: tips 提示 
涉及性能的时候，批量的大小很关键。如果你的批量太大，它们会占用过多的内存。如果它们太小，网络开销又会很大。最佳的平衡点，取决于文档的大小一—如果文档很大，每个批量中就少放几篇；如果文档很小，就多放几篇——以及集群的能力。一个拥有强劲机器的大规模集群可以更快地处理更大的批量请求，并且仍然保持良好的搜索服务性能。最后，你需要自行测试，发现适合你用例的最佳点。你可以从像每个批量 1000 篇小文档这样的值开始（如日志文件），然后逐步增加数量直到你无法获得明显的性能提升。同时，记得监控你的集群，我们会在第 11 章讨论监控相关的内容。
:::
### 使用批量的更新或删除
在单个批量中，你可以包含任意数量的 `index` 和 `create` 操作，同样也可以包含任意数量的 `update` 和 `delete` 操作。
`Update` 操作看上去和刚刚讨论的 `index`、`create` 操作差不多，除了你必须指定 `ID`。而且，按照更新的方式，文档的内容需要包含 `doc` 文档或者 `script` 脚本，就像第 3 章中你对于单个更新操作所做的那样。
`Delete` 操作和其他的有所不同，这是因为删除时不用提供文档内容。你只需要元数据这一行。和更新操作一样，必须包含文档的 `ID`。
在代码清单 10-3 中，有一个包含4 种操作的批量处理：`index`、`create`、`update` 和 `delete`。
::: warning 代码清单 10-3 Index、create、 update 和 delete 的批量
```
POST /get-together/_bulk
{"index":{}}
{"title":"Elasticsearch Bucharest"}
{"create":{}}
{"title":"Big Data in romania"}
{"update":{"_id":"11"}}
{"doc":{"created_on":"2014-05-06"}}
{"delete":{"_id":"10"}}
{
  "took" : 80,
  "errors" : false,
  "items" : [
    {
      "index" : {
        "_index" : "get-together",
        "_id" : "0gytToABfFQLtETF1J-h",
        "_version" : 1,
        "result" : "created",
        "_shards" : {
          "total" : 2,
          "successful" : 2,
          "failed" : 0
        },
        "_seq_no" : 18,
        "_primary_term" : 2,
        "status" : 201
      }
    },
    {
      "create" : {
        "_index" : "get-together",
        "_id" : "0wytToABfFQLtETF1J-h",
        "_version" : 1,
        "result" : "created",
        "_shards" : {
          "total" : 2,
          "successful" : 2,
          "failed" : 0
        },
        "_seq_no" : 19,
        "_primary_term" : 2,
        "status" : 201
      }
    },
    {
      "update" : {
        "_index" : "get-together",
        "_id" : "11",
        "_version" : 2,
        "result" : "updated",
        "_shards" : {
          "total" : 2,
          "successful" : 2,
          "failed" : 0
        },
        "_seq_no" : 20,
        "_primary_term" : 2,
        "status" : 200
      }
    },
    {
      "delete" : {
        "_index" : "get-together",
        "_id" : "10",
        "_version" : 2,
        "result" : "deleted",
        "_shards" : {
          "total" : 2,
          "successful" : 2,
          "failed" : 0
        },
        "_seq_no" : 21,
        "_primary_term" : 2,
        "status" : 200
      }
    }
  ]
}
```
:::
如果批量 `API` 接口可以用于合并多个索引、更新和删除操作，那么你也可以通过多条搜索和多条获取 `API` 接口，分别为搜索和获取请求做同样的事情，下面我们来看看。
## 多条搜索和多条获取 API 接口
使用多条搜索（`multisearch`）及多条获取（`multiget`）所带来的好处和批量相同：当你不得不进行多个 `search` 或 `get` 请求的时候，将它们合并在一起将会节省花费在网络延迟上的时间。
### 多条搜索
一次发送多条搜索请求的一个使用场景是你正在搜索不同类型的文档。例如，我们假设在 `get-together` 站点上有一个搜索框。你并不知道搜索是针对分组还是活动，所以准备同时搜索两者，并在用户界面上提供不同的标签页：一个用于显示分组的搜索结果，而另一个用于显示活动的搜索结果。这两个搜索应该有着完全不一样的评分机制，所以需要在不同的请求中执行，或者将这些请求合并在一个多条搜索请求中。
这个多条搜索 `API` 接口和批量 `API` 接口有很多相似之处。
- 访问了 `_msearch` 端点，在 `URL` 中你可以指定、也可以不指定索引。
- 每个请求有个两行的 `JSON` 字符串：第一行可能包含索引、路由值或搜索类型这样的参数——在单个请求的 `URI` 中你通常也会放入这些。第二行包含了查询的主体，通常是单个请求的有效负荷。
代码清单 10-4 展示了一个多条搜索请求的例子，它会搜索 `Elasticsearch` 相关的活动和分组。
::: warning 代码清单 10-4 一个多条搜索请求，它将查找关于 Elasticsearch 的活动和分组
```
POST _msearch
{"index":"get-together"}
{ "query": {"match":{"name":"elasticsearch"}}}
{"index":"get-together"}
{ "query": {"match":{"title":"elasticsearch"}}}
{
  "took" : 61,
  "responses" : [
    {
      "took" : 26,
      "timed_out" : false,
      "_shards" : {
        "total" : 2,
        "successful" : 2,
        "skipped" : 0,
        "failed" : 0
      },
      "hits" : {
        "total" : {
          "value" : 3,
          "relation" : "eq"
        },
        "max_score" : 1.2048764,
        "hits" : [
          {
            "_index" : "get-together",
            "_id" : "0AyoToABfFQLtETFnp-C",
            "_score" : 1.2048764,
            "_source" : {
              "name" : "Elasticsearch Bucharest"
            }
          }
        ]
      },
      "status" : 200
    },
    {
      "took" : 61,
      "timed_out" : false,
      "_shards" : {
        "total" : 2,
        "successful" : 2,
        "skipped" : 0,
        "failed" : 0
      },
      "hits" : {
        "total" : {
          "value" : 8,
          "relation" : "eq"
        },
        "max_score" : 0.72042507,
        "hits" : [
          {
            "_index" : "get-together",
            "_id" : "0gytToABfFQLtETF1J-h",
            "_score" : 0.72042507,
            "_source" : {
              "title" : "Elasticsearch Bucharest"
            }
          }
        ]
      },
      "status" : 200
    }
  ]
}
```
:::
### 多条获取
某些 `Elasticsearch` 系统之外的处理要求你在不进行任何搜索的前提下获取一组文档，这个时候多条获取就很有意义了。例如，你正在存储系统的度量指标，而时间戳作为文档 `ID`，你可以在不使用任何过滤器的情况下，检索特定时间的特定度量值。为了实现这一点，要调用 `_mget` 端点并发送包含索引和待查文档 `ID` 的 `docs` 数组，如代码清单 10-5 所示。
::: warning 代码清单 10-5 _mget 端点和包含索引和文档 ID 参数的 docs 数组
```
GET /_mget
{
  "docs":[
    {"_index":"get-gogether","_id":"1"},
    {"_index":"get-gogether","_id":"2"}
  ]
}
{
  "docs" : [
    {
      "_index" : "get-gogether",
      "_id" : "1",
      "error" : {
        "root_cause" : [
          {
            "type" : "index_not_found_exception",
            "reason" : "no such index [get-gogether]",
            "resource.type" : "index_expression",
            "resource.id" : "get-gogether",
            "index_uuid" : "_na_",
            "index" : "get-gogether"
          }
        ],
        "type" : "index_not_found_exception",
        "reason" : "no such index [get-gogether]",
        "resource.type" : "index_expression",
        "resource.id" : "get-gogether",
        "index_uuid" : "_na_",
        "index" : "get-gogether"
      }
    },
    {
      "_index" : "get-gogether",
      "_id" : "2",
      "error" : {
        "root_cause" : [
          {
            "type" : "index_not_found_exception",
            "reason" : "no such index [get-gogether]",
            "resource.ty pe" : "index_expression",
            "resource.id" : "get-gogether",
            "index_uuid" : "_na_",
            "index" : "get-gogether"
          }
        ],
        "type" : "index_not_found_exception",
        "reason" : "no such index [get-gogether]",
        "resource.type" : "index_expression",
        "resource.id" : "get-gogether",
        "index_uuid" : "_na_",
        "index" : "get-gogether"
      }
    }
  ]
}
```
:::
对于多数 `API` 接口而言，索引参数是可选的，因为你还可以将它们放在请求的 `URL` 中。当所有 `ID`（即文档）的索引都是相同的时候，建议你将他们放在 `URL` 中，然后将 `ID`放入 `ids` 数组，使得代码清单 10-5 中的请求更简短。
```
GET /get-together/_mget
{
  "ids":[1,2]
}
```
使用多条获取 `API` 将多个操作合并到同一个的请求中，这样做可能会使得你的应用程序变得稍微复杂一点，但是它会使得这此查询运行得更快，而且没有明显的成本。对于多条搜索和 `bulk` 批量 `API` 同样如此，而且为了充分地挖掘这些 `API` 的潜力，可以使用不同的请求大小进行实验，然后看看对于你的文档和硬件来说何种规模是最佳的。
下面，我们来看看在内部，`Elasticsearch` 是如何使用 `Lucene` 分段的形式来处理批量请求中的文档，以及如何调优这此过程来加速索引和搜索。