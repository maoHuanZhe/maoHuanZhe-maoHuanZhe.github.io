---
title: 提取词干
date: 2022-04-19 20:33:21
permalink: /pages/a43578/
categories:
  - Elasticsearch
  - 分析数据
tags:
  - 
author: 
  name: 樊光瑞
  link: https://github.com/maoHuanZhe
---

`提取词干` 是将单词缩减到基本或词根的形式。在搜索的时候，这种处理是非常方便的，因为这意味着用户可以匹配单词的复数，以及有同样词根的单词（因此名字称为 `提取词干`)。下面来看一个具体的例子。如果单词是 `administrations`，单词的词根是 `administr`，这让用户可以匹配所有同样词根的单词，如 `administrator`
`administration` `administrate`。提取词干是一种强有力的方法，使得搜索比僵硬的精确匹配更为灵活。

## 算法提取词干

通过算法提取词干，是为每个分词使用公式或一组规则来对其进行词干的获取。`Elasticsearch`提供 3 种不同的词干算法：`snowball` 过滤器、`porter_stem` 过滤器和 `kstem` 过滤器。它们的表现行为基本一致，不过在提取词干有多激进的方面有一些细微的差别。这里的 “激进”，是指相对于不激进的词干提取器，更为激进的词干提取器会砍掉单词更多的部分。表 5-1 展示了不同算法分词器之间的对比。

::: center

表 5-1 snowball、porter 和 kstem 的词干提取对比

| 词干提取器  | administrations | administrators | Administrate |
| ----------- | --------------- | -------------- | ------------ |
| snowball    | administr       | administr      | Administer   |
| porter_stem | administr       | administr      | Administer   |
| kstem       | administration  | administrator  | Administrate |

:::

为了看看词干提取器是如何工作的，可以使用分析 `API` 接口来指定它为分词过滤器。

```http
POST /_analyze
{
  "tokenizer": "standard",
  "filter": ["kstem"],
  "text": "administrators"
}
```

将 `snowball` 过滤器、`porter_stem` 或者 `kstem` 作为过滤器来测试一下效果。

作为算法提取词干的另一种替代方法，可以使用字典来提取词干，这是一种原始词和词干之间的一对一映射。

## 使用字典提取词干

有的时候，算法词干提取会以一种奇怪的方式来提取单词的词干，因为它们并不理解基层的语言。正因为此，存在更为精确的方式来提取词干，那就是使用单词字典。在 `Elasticsearch` 中，可以使用 `hunspell` 分词过滤器，结合一个字典，来处理词干。基于此，词干提取的质量就和所用字典的质量是直接相关的。词干提取器只能处理字典里存在的单词。
当创建一个 `hunspell` 分析器的时候，字典文件应该是在名为 `hunspell` 的目录里，并且 `hunspell`目录和 `elasticsearch.yml` 处于同一个目录中。在 `hunspell` 目录中，每种语言的字典是一个以其关联地区命名的目录。这里是如何使用 `hunspell` 分析器来创建索引的例子：

```http
PUT /hspell
{
  "settings": {
    "analysis": {
      "analyzer": {
        "hunAnalyzer": {
          "tokenizer": "standard",
          "filter": ["lowercase","hunFilter"]
        }
      },
      "filter": {
        "hunFilter": {
          "type": "hunspell",
          "locale": "en-US",
          "dedup": true
        }
      }
    }
  }
}
```

这个 `hunspell` 的字典文件应该是在 `<es-config-dir>/hunspell/en-US` 目录之中(使用 `Elasticsearch` 配置目录位置来替换 `<es-config-dir>`）。这里使用了 `en-US` 目录是因为 `hunspell`分析器是用于英文的，并且和前面例子中的 `locale` 设置相对应。

## 重写分词过滤器的词干提取

有的时候不想提取单词的词干，因为词干提取没有正确地处理这些单词，或者想对特定的单词进行精确匹配。那么就可以在分词过滤器链条中的词干过滤器之前，放置`关键词标记`(`kcyword marker`）分词过滤器，来达到这个目的。在关键词标记分词过滤器中，用户可以指定单词列表或者是包含单词列表的文件，让它们不被提取词干。

除了不让提取单词的词干，更有帮助的是手动指定一组用于词干提取的规则。用户可以使用 `stemmer override` 分词过滤器来实现。它允许用户指定这样的规则：`cats =>cat`。如果 `stemmer override` 发现一条规则并运用于一个单词上，那个单词就不会被任何其他词干提取器处理。

请记住，以上两个分词过滤器必须放置在任何其他词于过滤器之前，因为它们将保护词条之后不会被链条中其他的分词过滤器提取词干。

::: node 官方文档

[词干](https://www.elastic.co/guide/en/elasticsearch/reference/8.1/stemming.html)

[hunspell](https://www.elastic.co/guide/en/elasticsearch/reference/8.1/analysis-hunspell-tokenfilter.html)

[hunspell.github.io](http://hunspell.github.io/)

[词典下载地址](https://addons.mozilla.org/zh-CN/firefox/language-tools/)

:::
